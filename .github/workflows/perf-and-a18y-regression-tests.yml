name: Daily Performance & Accessibility Audit

on:
  schedule:
    - cron: '51 14 * * *'
  workflow_dispatch:

permissions:
  contents: write

env:
  SITE_URL: 'https://store.pricedb.io'
  HISTORY_DIR: 'hist'
  # Limit pages for debugging
  MAX_PAGES: 10

jobs:
  audit-and-compare:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Install Unlighthouse
        run: npm install -g @unlighthouse/cli puppeteer

      - name: Create Unlighthouse Config
        run: |
          cat <<EOF > unlighthouse.config.ts
          export default {
            site: '${{ env.SITE_URL }}',
            scanner: {
              device: 'mobile',
              samples: 3,
              maxRoutes: ${{ env.MAX_PAGES }}
            },
            discovery: {
              maxPages: ${{ env.MAX_PAGES }},
            },
            debug: true,
            outputPath: '.unlighthouse'
          }
          EOF

      - name: Run Unlighthouse CI
        # Explicitly use the config file
        run: unlighthouse-ci --config unlighthouse.config.ts --reporter json

      - name: Debug File Structure
        # This helps us see if the JSON is nested in a subfolder (common with unlighthouse)
        run: |
          echo "Listing .unlighthouse directory:"
          find .unlighthouse -maxdepth 4 || echo "find command failed"

      - name: Process Results & Compare History
        id: process
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');

            // --- Configuration ---
            const historyDir = process.env.HISTORY_DIR;
            const unlighthouseBaseDir = '.unlighthouse';
            const threshold = 2; 

            // --- Helpers ---
            const formatDate = (date) => date.toISOString().split('T')[0];
            const getScore = (val) => Math.round((val || 0) * 100);

            // Recursive function to find the ci-result.json file
            function findResultFile(dir) {
              if (!fs.existsSync(dir)) return null;
              const files = fs.readdirSync(dir);
              for (const file of files) {
                const fullPath = path.join(dir, file);
                const stat = fs.statSync(fullPath);
                if (stat.isDirectory()) {
                  const found = findResultFile(fullPath);
                  if (found) return found;
                } else if (file === 'ci-result.json' || file === 'unlighthouse.json') {
                  return fullPath;
                }
              }
              return null;
            }

            console.log("--- DEBUG START ---");

            // 1. Locate the JSON file
            console.log(`Searching for result file in ${unlighthouseBaseDir}...`);
            const jsonFilePath = findResultFile(unlighthouseBaseDir);
            
            if (!jsonFilePath) {
              console.error("âŒ CRITICAL: Could not find ci-result.json or unlighthouse.json anywhere in .unlighthouse/");
              core.setFailed("Missing Unlighthouse JSON output file");
              return;
            }
            console.log(`âœ… Found JSON results at: ${jsonFilePath}`);

            // 2. Read and Inspect Raw Data
            let rawData = [];
            try {
              const fileContent = fs.readFileSync(jsonFilePath, 'utf8');
              const jsonContent = JSON.parse(fileContent);
              
              // Check if it is an array or object
              if (Array.isArray(jsonContent)) {
                console.log(`JSON is an Array with length: ${jsonContent.length}`);
                rawData = jsonContent;
              } else if (jsonContent.routes && Array.isArray(jsonContent.routes)) {
                console.log(`JSON is an Object with .routes array length: ${jsonContent.routes.length}`);
                rawData = jsonContent.routes;
              } else {
                console.log("âš ï¸ JSON structure is unknown. Keys:", Object.keys(jsonContent));
                rawData = [];
              }
            } catch (e) {
              console.error(`âŒ Failed to parse JSON: ${e.message}`);
              core.setFailed("Invalid JSON");
              return;
            }

            if (rawData.length > 0) {
              console.log("--- SAMPLING DATA STRUCTURE (First Item) ---");
              console.log(JSON.stringify(rawData[0], null, 2));
            } else {
              console.error("âŒ Raw data array is empty.");
            }

            // 3. Process Data
            const todayData = [];
            let skippedCount = 0;

            console.log("--- PROCESSING ROUTES ---");
            rawData.forEach((route, index) => {
              // DEBUG: Log first 3 routes processing
              const isDebug = index < 3; 
              
              if (!route.path) {
                if(isDebug) console.log(`Skipping item ${index}: No 'path' property.`);
                skippedCount++;
                return;
              }

              if (!route.scores) {
                if(isDebug) console.log(`Skipping item ${index} (${route.path}): 'scores' property is undefined.`);
                // Log what keys exist instead
                if(isDebug) console.log(`Available keys: ${Object.keys(route)}`);
                skippedCount++;
                return;
              }

              // Extract scores
              const p = getScore(route.scores.performance);
              const a = getScore(route.scores.accessibility);
              const s = getScore(route.scores.seo);
              const b = getScore(route.scores['best-practices']);

              if(isDebug) console.log(`Item ${index} (${route.path}): Perf=${p}, Acc=${a}`);

              todayData.push({
                path: route.path,
                performance: p,
                accessibility: a,
                seo: s,
                bestPractices: b
              });
            });

            console.log(`--- PROCESSING SUMMARY ---`);
            console.log(`Total Routes Found: ${rawData.length}`);
            console.log(`Skipped (Invalid/No Scores): ${skippedCount}`);
            console.log(`Valid Rows Generated: ${todayData.length}`);

            if (todayData.length === 0) {
              console.error("âŒ No valid data rows were generated. CSV will be empty.");
              // Do not fail hard, so we can see logs, but warn heavily
            }

            // 4. Save CSV
            if (!fs.existsSync(historyDir)) {
              fs.mkdirSync(historyDir, { recursive: true });
            }

            const header = 'Path,Performance,Accessibility,SEO,Best Practices\n';
            const csvRows = todayData.map(r => 
              `${r.path},${r.performance},${r.accessibility},${r.seo},${r.bestPractices}`
            ).join('\n');
            
            const today = new Date();
            const todayStr = formatDate(today);
            const todayFile = path.join(historyDir, `${todayStr}.csv`);
            
            // fs.writeFileSync handles overwriting by default
            fs.writeFileSync(todayFile, header + csvRows);
            console.log(`âœ… Saved results to ${todayFile}`);

            // 5. Historical Comparison (Logic Preserved)
            const getPastDate = (daysAgo) => {
              const d = new Date();
              d.setDate(d.getDate() - daysAgo);
              return formatDate(d);
            };

            const loadCsvMap = (dateStr) => {
              const file = path.join(historyDir, `${dateStr}.csv`);
              if (!fs.existsSync(file)) return null;
              
              try {
                const content = fs.readFileSync(file, 'utf8').trim().split('\n');
                const map = new Map();
                content.slice(1).forEach(row => {
                  const cols = row.split(',');
                  if (cols.length >= 3) {
                    map.set(cols[0], { perf: parseInt(cols[1]), acc: parseInt(cols[2]) });
                  }
                });
                return map;
              } catch (e) {
                console.log(`Error reading history file ${file}: ${e.message}`);
                return null;
              }
            };

            const yesterdayStr = getPastDate(1);
            const lastWeekStr = getPastDate(7);

            const yesterdayMap = loadCsvMap(yesterdayStr);
            const lastWeekMap = loadCsvMap(lastWeekStr);

            let markdownReport = `### ðŸ“‰ Performance Regression Report (${todayStr})\n\n`;
            let regressionCount = 0;

            const checkRegression = (url, metricName, current, old, dateLabel) => {
              if (isNaN(current) || isNaN(old)) return;
              const diff = old - current;
              if (diff > threshold) {
                regressionCount++;
                markdownReport += `- âš ï¸ **${url}** - ${metricName} dropped by **${diff}** points vs ${dateLabel} (${old} -> ${current})\n`;
              }
            };

            todayData.forEach(page => {
              if (yesterdayMap && yesterdayMap.has(page.path)) {
                const y = yesterdayMap.get(page.path);
                checkRegression(page.path, 'Performance', page.performance, y.perf, 'Yesterday');
                checkRegression(page.path, 'Accessibility', page.accessibility, y.acc, 'Yesterday');
              }
              if (lastWeekMap && lastWeekMap.has(page.path)) {
                const w = lastWeekMap.get(page.path);
                checkRegression(page.path, 'Performance', page.performance, w.perf, 'Last Week');
                checkRegression(page.path, 'Accessibility', page.accessibility, w.acc, 'Last Week');
              }
            });

            if (regressionCount === 0) {
              markdownReport += "âœ… No significant regressions detected.";
            } else {
              markdownReport += `\n**Total Regressions:** ${regressionCount}`;
            }

            await core.summary.addRaw(markdownReport).write();
            core.setOutput('today_file', todayFile);
            console.log("--- DEBUG END ---");

      - name: Commit CSV to Repo
        run: |
          git config --global user.name "GitHub Action Runner"
          git config --global user.email "actions@github.com"
          git add ${{ env.HISTORY_DIR }}/*.csv
          git diff --quiet && git diff --staged --quiet || (git commit -m "Add performance audit for $(date +'%Y-%m-%d')" && git push)

      - name: Upload CSV Artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-audit-debug
          path: ${{ steps.process.outputs.today_file }}
