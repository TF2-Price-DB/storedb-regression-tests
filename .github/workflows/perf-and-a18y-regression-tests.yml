name: Daily Performance & Accessibility Audit

on:
  schedule:
    - cron: '51 14 * * *'
  workflow_dispatch:

permissions:
  contents: write

env:
  SITE_URL: 'https://store.pricedb.io'
  HISTORY_DIR: 'hist'
  # Limit pages for debugging
  MAX_PAGES: 5

jobs:
  audit-and-compare:
    runs-on: blacksmith-4vcpu-ubuntu-2404
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Install Unlighthouse
        run: npm install -g @unlighthouse/cli puppeteer

      - name: Create Unlighthouse Config
        run: |
          cat <<EOF > unlighthouse.config.ts
          export default {
            site: '${{ env.SITE_URL }}',
            scanner: {
              device: 'mobile',
              samples: 2,
              maxRoutes: ${{ env.MAX_PAGES }},
              skipJavascript: false,
              timeout: 900000, 
            },
            puppeteerOptions: {
              timeout: 900000,
            },
            discovery: {
              maxPages: ${{ env.MAX_PAGES }},
            },
            debug: true,
            outputPath: '.unlighthouse'
          }
          EOF

      - name: Run Unlighthouse CI
        run: unlighthouse-ci --config unlighthouse.config.ts --reporter json

      - name: Process Results & Compare History
        id: process
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');

            // --- Configuration ---
            const historyDir = process.env.HISTORY_DIR;
            const unlighthouseBaseDir = '.unlighthouse';
            const threshold = 2; 

            // --- Helpers ---
            const formatDate = (date) => date.toISOString().split('T')[0];
            const getScore = (val) => Math.round((val || 0) * 100);

            // Recursive function to find the ci-result.json file
            function findResultFile(dir) {
              if (!fs.existsSync(dir)) return null;
              const files = fs.readdirSync(dir);
              for (const file of files) {
                const fullPath = path.join(dir, file);
                const stat = fs.statSync(fullPath);
                if (stat.isDirectory()) {
                  const found = findResultFile(fullPath);
                  if (found) return found;
                } else if (file === 'ci-result.json' || file === 'unlighthouse.json') {
                  return fullPath;
                }
              }
              return null;
            }

            // 1. Locate the JSON file
            console.log(`Searching for result file in ${unlighthouseBaseDir}...`);
            const jsonFilePath = findResultFile(unlighthouseBaseDir);
            
            if (!jsonFilePath) {
              core.setFailed("Missing Unlighthouse JSON output file");
              return;
            }
            console.log(`âœ… Found JSON results at: ${jsonFilePath}`);

            // 2. Read Data
            let rawData = [];
            try {
              const fileContent = fs.readFileSync(jsonFilePath, 'utf8');
              const jsonContent = JSON.parse(fileContent);
              rawData = Array.isArray(jsonContent) ? jsonContent : (jsonContent.routes || []);
            } catch (e) {
              core.setFailed(`Failed to parse JSON: ${e.message}`);
              return;
            }

            // 3. Process Data
            const todayData = [];
            
            rawData.forEach((route, index) => {
              if (!route.path) return;

              // FIX: Handle Flat Structure vs Nested Structure
              // The logs showed the data is flat (e.g. route.performance), not nested in scores
              const getVal = (key) => {
                if (route[key] !== undefined) return route[key];
                if (route.scores && route.scores[key] !== undefined) return route.scores[key];
                return 0;
              };

              // Extract scores using the helper
              const p = getScore(getVal('performance'));
              const a = getScore(getVal('accessibility'));
              const s = getScore(getVal('seo'));
              const b = getScore(getVal('best-practices'));

              // Only add if we actually found data (assuming 0 might be valid but rare for all)
              // We check if performance is > 0 to imply a successful scan
              if (p > 0 || a > 0) {
                 todayData.push({
                    path: route.path,
                    performance: p,
                    accessibility: a,
                    seo: s,
                    bestPractices: b
                 });
              } else {
                 console.log(`Skipping ${route.path} - Seems like 0 scores (Scan failed?)`);
              }
            });

            console.log(`Valid Rows Generated: ${todayData.length}`);

            if (todayData.length === 0) {
              core.setFailed("No valid data rows were generated.");
              return;
            }

            // 4. Determine Filename (Manual vs Schedule)
            if (!fs.existsSync(historyDir)) {
              fs.mkdirSync(historyDir, { recursive: true });
            }

            const now = new Date();
            const dateStr = formatDate(now);
            let filename = `${dateStr}.csv`;

            // If manually triggered, append timestamp to avoid overwriting daily log
            if (context.eventName === 'workflow_dispatch') {
               const timeStr = now.toISOString().split('T')[1].split('.')[0].replace(/:/g, '-');
               filename = `${dateStr}_${timeStr}.csv`;
               console.log("â„¹ï¸ Manual trigger detected: using timestamped filename.");
            }

            const finalFilePath = path.join(historyDir, filename);

            // 5. Save CSV
            const header = 'Path,Performance,Accessibility,SEO,Best Practices\n';
            const csvRows = todayData.map(r => 
              `${r.path},${r.performance},${r.accessibility},${r.seo},${r.bestPractices}`
            ).join('\n');
            
            fs.writeFileSync(finalFilePath, header + csvRows);
            console.log(`âœ… Saved results to ${finalFilePath}`);

            // 6. Historical Comparison 
            // We only compare against standard daily files (YYYY-MM-DD.csv), not manual ones
            const getPastDate = (daysAgo) => {
              const d = new Date();
              d.setDate(d.getDate() - daysAgo);
              return formatDate(d);
            };

            const loadCsvMap = (targetDateStr) => {
              const file = path.join(historyDir, `${targetDateStr}.csv`);
              if (!fs.existsSync(file)) return null;
              
              try {
                const content = fs.readFileSync(file, 'utf8').trim().split('\n');
                const map = new Map();
                content.slice(1).forEach(row => {
                  const cols = row.split(',');
                  if (cols.length >= 3) {
                    map.set(cols[0], { perf: parseInt(cols[1]), acc: parseInt(cols[2]) });
                  }
                });
                return map;
              } catch (e) {
                return null;
              }
            };

            const yesterdayStr = getPastDate(1);
            const lastWeekStr = getPastDate(7);

            const yesterdayMap = loadCsvMap(yesterdayStr);
            const lastWeekMap = loadCsvMap(lastWeekStr);

            let markdownReport = `### ðŸ“‰ Performance Regression Report (${filename})\n\n`;
            let regressionCount = 0;

            const checkRegression = (url, metricName, current, old, dateLabel) => {
              if (isNaN(current) || isNaN(old)) return;
              const diff = old - current;
              if (diff > threshold) {
                regressionCount++;
                markdownReport += `- âš ï¸ **${url}** - ${metricName} dropped by **${diff}** points vs ${dateLabel} (${old} -> ${current})\n`;
              }
            };

            todayData.forEach(page => {
              if (yesterdayMap && yesterdayMap.has(page.path)) {
                const y = yesterdayMap.get(page.path);
                checkRegression(page.path, 'Performance', page.performance, y.perf, 'Yesterday');
                checkRegression(page.path, 'Accessibility', page.accessibility, y.acc, 'Yesterday');
              }
              if (lastWeekMap && lastWeekMap.has(page.path)) {
                const w = lastWeekMap.get(page.path);
                checkRegression(page.path, 'Performance', page.performance, w.perf, 'Last Week');
                checkRegression(page.path, 'Accessibility', page.accessibility, w.acc, 'Last Week');
              }
            });

            if (regressionCount === 0) {
              markdownReport += "âœ… No significant regressions detected.";
            } else {
              markdownReport += `\n**Total Regressions:** ${regressionCount}`;
            }

            await core.summary.addRaw(markdownReport).write();
            core.setOutput('csv_file', finalFilePath);

      - name: Commit CSV to Repo
        run: |
          git config --global user.name "GitHub Action Runner"
          git config --global user.email "actions@github.com"
          git add ${{ steps.process.outputs.csv_file }}
          git diff --quiet && git diff --staged --quiet || (git commit -m "Add performance audit" && git push)

      - name: Upload CSV Artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-audit-result
          path: ${{ steps.process.outputs.csv_file }}
